{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from rdkit import Chem\n",
    "import polyfingerprints as pfp\n",
    "import warnings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# always put ([*]) as the first of the side chains\n",
    "def find_side_chain_to_left(psmiles: str, star_pos: int) -> str:\n",
    "    if not \")([*])\" in psmiles:\n",
    "        return psmiles\n",
    "    stack = []\n",
    "    side_chain = []\n",
    "    r_star_pos = len(psmiles)-star_pos # reverse the position\n",
    "    for pos, i in enumerate(reversed(psmiles)):\n",
    "        if i == \")\":\n",
    "            stack.append(pos)\n",
    "        if i == \"(\":\n",
    "            if len(stack) == 1:\n",
    "                side_chain.append((stack.pop(), pos))\n",
    "                if psmiles[-pos-2] != \")\": # when the side chain of the star is left we do not need to keep collecting other side chains\n",
    "                    \n",
    "                    for nr, side in enumerate(side_chain): # sort the side chain so the one with the star is first\n",
    "                        if r_star_pos in range(side[0], side[1]+1):\n",
    "                            side_chain = [side_chain[nr]] + side_chain[nr+1:] + side_chain[:nr]\n",
    "                            break\n",
    "                    else: # if the star is not in the side chain reset the collection and continue with next side chain\n",
    "                        side_chain = []\n",
    "                        continue\n",
    "                    break\n",
    "            else:\n",
    "                stack.pop()\n",
    "    \n",
    "    end_chain = -min(min(side_chain))\n",
    "    if end_chain == 0:\n",
    "        end_chain = None\n",
    "    \n",
    "    ordered_side_chain_string = \"\".join([psmiles[-end-1:-start] if start != 0 else psmiles[-end-1:] for start, end in side_chain])\n",
    "    # how print anything else beside the ordered side chains:\n",
    "    if end_chain:\n",
    "        return psmiles[:-max(max(side_chain))-1] + ordered_side_chain_string + psmiles[end_chain:]\n",
    "    else:\n",
    "        return psmiles[:-max(max(side_chain))-1] + ordered_side_chain_string\n",
    "            "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def harmonize_PSMILES(psmiles: str) -> str:\n",
    "    # make sure all stars are enclosed in square brackets but not double enclosed\n",
    "    corr_enclosed = psmiles.count(\"[*]\")\n",
    "    if corr_enclosed < 2:\n",
    "        if corr_enclosed == 0:\n",
    "            psmiles = psmiles.replace(\"*\", \"[*]\")\n",
    "        else:\n",
    "            front_a = psmiles.find(\"*\")\n",
    "            if psmiles.find(\"[*]\") > front_a: # in case the first star is un-enclosed\n",
    "                psmiles = psmiles.replace(\"*\", \"[*]\", 1)\n",
    "            else:\n",
    "                psmiles = psmiles.rpartition(\"*\")[0] + \"[*]\" + psmiles.rpartition(\"*\")[2]        \n",
    "\n",
    "    # check if the asterisks are set as a side chain if they are not on the end and parenthesize them otherwise.\n",
    "    second_star_q = 0\n",
    "    for pos, symbol in enumerate(psmiles):\n",
    "        if symbol == \"*\":\n",
    "            if second_star_q == 0: # skip the first star\n",
    "                second_star_q = 1\n",
    "            else: # bracket the second star if necessary\n",
    "                if pos == len(psmiles)-2: \n",
    "                    if psmiles[pos-2] == \")\": # if the asterisk is at the end (before its square bracket) AND not on a side chain (a \")\" before it) it does not need bracketing\n",
    "                        psmiles = psmiles[:pos-1] + \"([\" + psmiles[pos] + \"])\"\n",
    "                    \n",
    "                else:\n",
    "                    if psmiles[pos-2] != \"(\" and psmiles[pos+2] != \")\":\n",
    "                        psmiles = psmiles[:pos-1] + \"([\" + psmiles[pos] + \"])\" + psmiles[pos+2:]\n",
    "                psmiles = find_side_chain_to_left(psmiles, pos)\n",
    "                break\n",
    "    return psmiles"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def parse_p_to_explicit_smiles(psmiles: str) -> str:\n",
    "    h_psmiles = harmonize_PSMILES(psmiles)\n",
    "\n",
    "    # second create a mol object\n",
    "    mol = Chem.MolFromSmiles(h_psmiles)\n",
    "    if mol is None:\n",
    "        print(f\"{psmiles} harmonized to {h_psmiles} is not a valid PSMILES string for parsing to explicit SMILES\")\n",
    "        return \"\"\n",
    "\n",
    "    # iterate over the atoms catching the position of the C Atoms following and preceding [*] and their valence\n",
    "    star_index = []\n",
    "    valence = []\n",
    "    atomsymbols = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atomsymbol = atom.GetSymbol()\n",
    "        # if atom.GetIsAromatic():\n",
    "        #     atomsymbol = atomsymbol.lower()\n",
    "        atomsymbols.append(atomsymbol)\n",
    "        if atomsymbol == \"*\":\n",
    "            star_index.append(atom.GetIdx())\n",
    "        valence.append(atom.GetExplicitValence())\n",
    "\n",
    "    if len(star_index) != 2:\n",
    "        # raise a type error\n",
    "        raise TypeError (f\"{__name__} cannot handle (ladder) polymers with {len(star_index)} * in the PSMILES string!\")\n",
    "    \n",
    "    c_index = [star_index[0]+1, star_index[1]-1] # cannot do that atom symbols are not in order\n",
    "    \n",
    "    # the current valence of the C atoms is the explicit minus the [*] connection/-1\n",
    "    def valence_change(val):\n",
    "        return 4 - val\n",
    "    h_num = []\n",
    "    for sy, val in zip(atomsymbols, valence):  # number of H atoms assuming C atoms\n",
    "        if sy == \"C\":\n",
    "            h_num.append(valence_change(val))\n",
    "        else:\n",
    "            h_num.append(0)\n",
    "\n",
    "    # replace C atoms with the explicit hydrogen count and catch the special case of parenthesised like e.g.([*]) and parenthesise the dangling part of the smiles string to the end after that C atom like [*]CC([*])(C)C(=O)OC -> [CH2][C](C)(C(=O)OC) (attention to the bracket pair ending with the last symbol \")\")\n",
    "\n",
    "    atomsymbols = [_atom if _atom != \"*\" else r\"\\*\" for _atom in atomsymbols] # escape the * for the regex\n",
    "\n",
    "    # create a dict of atom index and index of it's symbol in the string\n",
    "    atom_positions = [m.start() for m in re.finditer(r\"(\"+'|'.join(atomsymbols)+\")\", h_psmiles.upper())]\n",
    "    atom_string_map = {atom_symbol_nr:string_pos for atom_symbol_nr, string_pos in zip(range(len(atomsymbols)), atom_positions)}\n",
    "    c_str_indexes = [atom_string_map[_c_index] for _c_index in c_index]\n",
    "    c_str_h_num = {atom_string_map[_c_index]:h_num[_c_index] for _c_index in c_index} # \n",
    "\n",
    "    smiles_reconstruction = \"\"\n",
    "    for idx, character in enumerate(h_psmiles):\n",
    "        if idx in c_str_indexes:\n",
    "            smiles_reconstruction += f\"[CH{c_str_h_num[idx]}]\" if c_str_h_num[idx] > 0 else f\"[{character}]\"\n",
    "        else:\n",
    "            smiles_reconstruction += character\n",
    "\n",
    "    # throw warning if the star is not directly behind the monomer-connecting C atom\n",
    "    if \")[*]\" in smiles_reconstruction:\n",
    "        print(f\"{psmiles} has a star not directly behind the monomer-connecting C atom!\")\n",
    "    \n",
    "    smiles_reconstruction = smiles_reconstruction.replace(\"([*])\", \"\")\n",
    "    smiles_reconstruction = smiles_reconstruction.replace(\"[*]\", \"\")\n",
    "\n",
    "    return smiles_reconstruction\n",
    "\n",
    "# for test_PSMILE in ([\"[*]CC[*](C(=O)OC1C[C@H]2CC[C@]1(C)C2(C)C)\", \n",
    "#                       \"CCCCC(COC(=O)C(*)C*)CC\", \"*CC(c1c(Cl)cccc1)*\", \"[*]CC(C)([*])(C(=O)OC)\", \"[*]OC(CC)CC(=O)*\", \"*C(=O)CC(CCC)O*\", \"[*]CC([*])(C)(C(=O)OC)\", \"*OC(CCC(c1ccccc1))CC(=O)O*\", \"[*]CC([*])(C)(C(=O)OC)\", \"*CC([*])(C)(C#N)\", \"[*]CC([*])(c1ccccc1)\",\"[*]CC[*](C)(C(=O)Oc1ccccc1)\", \"[*]C1=CC=C([*])(N1)\"\n",
    "#     ]):\n",
    "#     print(test_PSMILE + \" parsing...\")\n",
    "#     parsed_to_explicit = parse_p_to_explicit_smiles(test_PSMILE)\n",
    "#     print(pfp.test_polymer_smiles(parsed_to_explicit), parsed_to_explicit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dict of weird PSMILES strings and their proposed \"right\" writing:\n",
    "illegal_PSMILES = {\n",
    "    \"[*]CC[*](C)(C(=O)OC)\": \"[*]CC([*])(C)(C(=O)OC)\",\n",
    "    \"* C=C*\": \"*CC*\", # etylene\n",
    "    \"*C#C\" : \"[*]C=C[*]\", # acetylene\n",
    "    \"*OC(CCC(c1ccccc1))CC(=O)O*\": \"[*]OC(CCC(c1ccccc1))CC(=O)C[*]\", # dunno what to do with the source, the autors at https://pubs.acs.org/doi/10.1021/bm010018h do not make it very clear and propably have some mistake in their structure, but it should be some polyhydroxy propionate\n",
    "    \"*C=CC(=O)OC#N*\": \"[*]CC([*])(C(=O)OCCCC)(C#N)\", # cyanoacrylate (superglue) !also added the butylcyanoacrylat bec it has a specific tg of 74Â°C \n",
    "    \"*CC(=C)C#N*\": \"[*]CC([*])(C)(C#N)\", # methacrylonitrile\n",
    "    \"CC(c1cc(Cl)cccc1)\": \"[*]CC([*])(c1cc(Cl)ccc1)\",\n",
    "    \"[*]CC[*](c1ccccc1)\":\"[*]CC([*])(c1ccccc1)\",\n",
    "    \"*CC(c1c(Cl)ccccc1)*\":\"*CC(c1c(Cl)cccc1)*\",\n",
    "    \"*COCCCCCC(C)=O*\":\"[*]CCCCCC(=O)O[*]\", # poly(e-caprolactone) The dispersity seems to be calculated in a wrong way Mn is 530 to 630,000 Mw is 10,000 to 200,000 the dispersity is proclaimed to be 1.08-1.53 instead I have no idea how they compute that instead of 18.868 to 0.317 (which obviously makes no sense)\n",
    "    \"*[NH2+]1C=CC=C1*\":\"[*]C1=CC=C([*])(N1)\", # pyrrole\n",
    "    \"*ClC=C*\":\"[*]CC([*])(Cl)\", # vinylchloride\n",
    "    \"*CCF*\":\"[*]CC[*](F)\", # vinylfluoride\n",
    "    \"*[H]OC(CC)CC(O)=O*\": \"[*]OC(CC)CC([*])(=O)\", # (3HV) 3-hydroxyvalerate\n",
    "    \"*CC(=C)C(=O)OCC1CO1*\": \"[*]CC([*])(C)(C(=O)OCC1OC1)\", # glycidyl methacrylate\n",
    "    \"*CC(c1cc(Cl)cccc1)*\": \"*CC(c1cc(Cl)ccc1)*\",\n",
    "    \"*CC(c1ccc(Cl)ccc1)*\": \"*CC(c1ccc(Cl)cc1)*\",\n",
    "    \"*CC(c1ccc(CN)ccc1)*\": \"*CC(c1ccc(CN)cc1)*\",\n",
    "    \"*CC(C)(c1cccccc1)*\": \"*CC(C)(c1ccccc1)*\",\n",
    "    \"*CC(c1ccc(C)ccc1)*\": \"*CC(c1ccc(C)cc1)*\",\n",
    "    \"CCC(C)C*C(c1ccc(OC)ccc1)*\": \"*C(C(C)CC)C(*)(c1ccc(OC)cc1)\",\n",
    "    \"*CC(c1cccccc1)*\": \"*CC(c1ccccc1)*\",\n",
    "    \n",
    "    # for larger sets with the following sample type canonicalizing the PSMILES is automatically possible with the canonicalize package \n",
    "    #     (the longest chain will be found by replacing the * with a long C chain and canonicalizing then before re-replacing)\n",
    "    \"CCOC(=O)C(C*)*\": \"*CC(*)(C(=O)OCC)\",\n",
    "    \"CCCCOC(=O)C(C*)*\":\"*CC(*)(C(=O)OCCCC)\",\n",
    "    \"CCCCC(COC(=O)C(C*)*)CC\":\"*CC(*)(C(=O)OCC(CC)CCCC)\",\n",
    "    \"CCCCCCCCCOC(=O)C(C*)*\":\"*CC(*)(C(=O)OCCCCCCCCC)\",\n",
    "    \"CCCCCCCCOC(=O)C(C*)*\":\"*CC(*)(C(=O)OCCCCCCCC)\",\n",
    "    \"CCCCOC(=O)C(C*)(C)*\":\"*CC(*)(C)(C(=O)OCCCC)\",\n",
    "    \"CCCCCCCCCCOC(=O)C(C*)(C)*\":\"*CC(*)(C)(C(=O)OCCCCCCCCCC)\",\n",
    "    \"CCOC(=O)C(C*)(C)*\":\"*CC(*)(C)(C(=O)OCC)\",\n",
    "    \"CCCCCCOC(=O)C(C*)(C)*\":\"*CC(*)(C)(C(=O)OCCCCCC)\",\n",
    "    \"OCCOC(=O)C(C*)(C)*\":\"*CC(*)(C)(C(=O)OCCO)\",\n",
    "    \"*C(C(=O)O)(C*)C\":\"*CC(*)(C)(C(=O)O)\",\n",
    "    \"CCCCCCCCCCCCCCCCCCOC(=O)C(C*)(C)*\":\"*CC(*)(C)(C(=O)OCCCCCCCCCCCCCCCCCC)\",\n",
    "    \"CCCOC(=O)C(C*)(C)*\":\"*CC(*)(C)(C(=O)OCCC)\",\n",
    "    }\n",
    "\n",
    "# for k, v in illegal_PSMILES.items():\n",
    "#     display(Chem.MolFromSmiles(v))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def convert_explicit_SMILES_to_PSMILES(explicit_SMILES: str, chain_pos: str = \"monomer\"):\n",
    "    all_explicits = re.findall(r\"\\[[^\\]\\*]*\\]\", explicit_SMILES)\n",
    "    replacements = [radical.replace(\"[\", \"\").replace(\"]\", \"\") for radical in all_explicits]\n",
    "    replacements = [re.sub(\"H[0-9]?\", \"\", radical) for radical in replacements]\n",
    "    if len(all_explicits) == 0:\n",
    "        warnings.warn(f\"No explicits found in {explicit_SMILES}\")\n",
    "        return explicit_SMILES\n",
    "    PSMILES = explicit_SMILES\n",
    "    \n",
    "    # if the replacement is not at the end or beginning it needs brackets\n",
    "    end_q = [(PSMILES.find(expl) == 0 or PSMILES.rfind(expl) == (len(PSMILES)-len(expl))) for expl in all_explicits]\n",
    "    \n",
    "    first = True\n",
    "    for edge, expl, repl in zip(end_q, all_explicits, replacements):\n",
    "        if first:\n",
    "            if edge:\n",
    "                repl = \"[*]\" + repl\n",
    "                first = False\n",
    "            else:\n",
    "                repl = repl + \"([*])\"\n",
    "                first = False\n",
    "            PSMILES = PSMILES.replace(expl, repl, 1)\n",
    "        else:\n",
    "            if edge:\n",
    "                repl = repl + \"[*]\"\n",
    "            else:\n",
    "                repl = repl + \"([*])\"\n",
    "            PSMILES = PSMILES.replace(expl, repl, 1)\n",
    "            break\n",
    "    \n",
    "    match chain_pos:\n",
    "        case \"monomer\":                   \n",
    "            if len(all_explicits) != 2:\n",
    "                warnings.warn(\"\\n\" + explicit_SMILES + \": \" + \"Too many OR little explicits found. Is there a radical in the monomer, or is this an end group?\" +\n",
    "                              \" Is \" + \"\\n\" + PSMILES + \" the right replacement?\")\n",
    "        case \"end\":            \n",
    "            if len(all_explicits) != 1:\n",
    "                warnings.warn(\"\\n\" + explicit_SMILES + \": \" + \"None or too many explicits found. Is there a radical in the end group, or is it a monomer?\" +\n",
    "                              \" Is \" + \"\\n\" + PSMILES + \" the right replacement?\")\n",
    "\n",
    "#     return PSMILES\n",
    "# for test_exp_SMILES in [\"[CH2][C](C)(C(=O)OC1C[C@H]2CC[C@]1(C)C2(C)C)\", \"[O]CCC[C](=O)\",\"[O]CCC[C]\", \"[C]CCC[C]\", \"C([CH])CSC[CH2]\"]:\n",
    "#     print(test_exp_SMILES + \" converting...\")\n",
    "#     print(convert_explicit_SMILES_to_PSMILES(test_exp_SMILES))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "homo_p = r\"new_final_homo.csv\"\n",
    "copo_p = r\"copo_final.csv\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# parse PSMILES to Explicit and back to PSMILES for unification\n",
    "for dt_p in [homo_p, copo_p]:\n",
    "    dt = pd.read_csv(dt_p)\n",
    "    psmiles_columns = [column for column in dt.columns if \"psmiles\" in column.lower()]\n",
    "\n",
    "    for psmiles_column in psmiles_columns:\n",
    "        dt[psmiles_column+\"_reparsed\"] = dt[psmiles_column].apply(\n",
    "            lambda y: harmonize_PSMILES(\n",
    "                convert_explicit_SMILES_to_PSMILES(\n",
    "                parse_p_to_explicit_smiles(illegal_PSMILES[y]) if y in illegal_PSMILES.keys() else parse_p_to_explicit_smiles(y))))\n",
    "    pd.DataFrame.to_csv(dt,\"reparsed_PSMILES_\" + dt_p, index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_FPs = {}\n",
    "for dt_p in [homo_p, copo_p]:\n",
    "    dt = pd.read_csv(dt_p)\n",
    "    psmiles_columns = [column for column in dt.columns if \"psmiles\" in column.lower()]\n",
    "    if not any([\"molpercent\" in column.lower() for column in dt.columns]):\n",
    "        dt[\"molpercent_rep_u1\"]=1\n",
    "    molfrac_columns = [column for column in dt.columns if \"molpercent\" in column.lower()]\n",
    "    print(psmiles_columns, molfrac_columns)\n",
    "    exp_column_list = []\n",
    "    for psmiles_column in psmiles_columns:\n",
    "        dt[psmiles_column+\"_to_explicit_SMILES\"] = dt[psmiles_column].apply(\n",
    "            lambda y: parse_p_to_explicit_smiles(illegal_PSMILES[y]) if y in illegal_PSMILES.keys() else parse_p_to_explicit_smiles(y))\n",
    "        exp_column_list.append(psmiles_column+\"_to_explicit_SMILES\")\n",
    "    \n",
    "    \n",
    "    mono_molfrac_list_tuples = [(mon, molfrac) for mon, molfrac in zip(exp_column_list, molfrac_columns)]\n",
    "    pfpdata = pfp.loader.df_loader(df=dt,\n",
    "                         repeating_unit_columns=mono_molfrac_list_tuples,\n",
    "                         mw_column=\"Mn\",\n",
    "                         additional_columns=[\"PDI\"]\n",
    "                         )\n",
    "    all_FPs[dt_p] = pfpdata\n",
    "    \n",
    "# out of the loop so reduction can take place over the combined dataset    \n",
    "len_pfp_sets = {key:len(values) for key, values in all_FPs.items()}\n",
    "\n",
    "combined_pfps = [pfp for pfp_list in all_FPs.values() for pfp in pfp_list] # flatten the list\n",
    "reduced_combined_pfps, mask = pfp.reduce_pfp_in_dataset(combined_pfps) # reduce the pfps and split them back into the dictionary\n",
    "# split the reduced pfps back into the datasets\n",
    "\n",
    "new_concise_csv_names = {key: val for key, val in zip([homo_p, copo_p], [\"homo-p_view_data.csv\", \"co-p_view_data.csv\"])}\n",
    "new_train_data_names = {key: val for key, val in zip([homo_p, copo_p], [\"homo-p_train_data.pckl\", \"co-p_train_data.pckl\"])}\n",
    "\n",
    "for dt_p in [homo_p, copo_p]:\n",
    "    dt = pd.read_csv(\"reparsed_PSMILES_\" + dt_p)\n",
    "    respective_pfp_set = reduced_combined_pfps[:len_pfp_sets[dt_p]]\n",
    "    reduced_combined_pfps = reduced_combined_pfps[len_pfp_sets[dt_p]:]\n",
    "    \n",
    "    dt.reset_index(drop=True, inplace=True)\n",
    "    dt[\"pfp\"] = [pfpdat[\"pfp\"] for pfpdat in respective_pfp_set]\n",
    "    pd.to_pickle(dt, new_train_data_names[dt_p])\n",
    "    dt.to_csv(new_concise_csv_names[dt_p], index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "testdf = pd.read_pickle(\"co-p_train_data.pckl\")\n",
    "testdf.reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
